{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "#from IPython.display import display\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "#from sklearn.model_selection import cross_val_score, train_test_split\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "#from sklearn.metrics import mean_squared_error, make_scorer\n",
    "#from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from keras.layers import Embedding, Input, Dense\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "'tra' : pd.read_csv('/Users/suzukishinji/kaggle/recluit/tra_gw.csv'),#1回目は513店舗#2回目は316\n",
    "'tes' : pd.read_csv('/Users/suzukishinji/kaggle/recluit/tes_gw.csv'),\n",
    "    \n",
    "'ar':pd.read_csv('/Users/suzukishinji/kaggle/recluit/air_reserve.csv'),\n",
    "'as' : pd.read_csv('/Users/suzukishinji/kaggle/recluit/air_store_info.csv'),\n",
    "'hol' : pd.read_csv('/Users/suzukishinji/kaggle/recluit/date_info.csv').rename(columns ={'calendar_date':'visit_date'}),\n",
    "'hr' : pd.read_csv('/Users/suzukishinji/kaggle/recluit/hpg_reserve.csv'),\n",
    "'hs' : pd.read_csv('/Users/suzukishinji/kaggle/recluit/hpg_store_info.csv'),\n",
    "'id' : pd.read_csv('/Users/suzukishinji/kaggle/recluit/store_id_relation.csv')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6793, 3)\n",
      "(18062, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data['tra'].shape)\n",
    "print(data['tes'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['hr'] = pd.merge(data['hr'], data['id'], how = 'inner', on = ['hpg_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in ['ar', 'hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_dow'] = data[df]['visit_datetime'].dt.dayofweek\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r:(r['visit_datetime']- r['reserve_datetime']).days, axis = 1)\n",
    "    data[df] = data[df][data[df]['reserve_datetime_diff'] > data[df]['visit_dow']]\n",
    "    tmp1 = data[df].groupby(['air_store_id', 'visit_datetime'], as_index =False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns = {'visit_datetime':'visit_date', 'reserve_datetime_diff':'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id', 'visit_datetime'], as_index =False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns = {'visit_datetime':'visit_date', 'reserve_datetime_diff':'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how = 'inner', on = ['air_store_id', 'visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0\n",
       "1  air_00a91d42b08b08d9_2017-04-24         0\n",
       "2  air_00a91d42b08b08d9_2017-04-25         0\n",
       "3  air_00a91d42b08b08d9_2017-04-26         0\n",
       "4  air_00a91d42b08b08d9_2017-04-27         0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tes'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_stores = data['tes']['air_store_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores = pd.concat([pd.DataFrame({'air_store_id':unique_stores, 'dow':[i]*len(unique_stores)}) for i in range(7)], axis =0, ignore_index = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#曜日だけでなく、月も追加\n",
    "stores_m = pd.concat([pd.DataFrame({'air_store_id':unique_stores, 'month':[i]*len(unique_stores)}) for i in range(1,13)], axis =0, ignore_index = True).reset_index(drop = True)\n",
    "stores = pd.merge(stores_m, stores,on=('air_store_id'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].min().rename(columns = {'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].median().rename(columns = {'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].max().rename(columns = {'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].count().rename(columns = {'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#曜日だけでなく、ID×月も追加\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].min().rename(columns = {'visitors':'m_min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'m_mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].median().rename(columns = {'visitors':'m_median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].max().rename(columns = {'visitors':'m_max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].count().rename(columns = {'visitors':'m_count_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = data['as'].groupby(['air_genre_name','air_area_name'], as_index = False)['air_store_id'].count().rename(columns = {'air_store_id':'genre_in_area'})\n",
    "data['as']= pd.merge(data['as'], tmp, how ='left', on = ['air_genre_name','air_area_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores = pd.merge(stores, data['as'], how= \"left\", on = ['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/', ' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-', ' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name' + str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ' '))\n",
    "    stores['air_area_name' + str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ' '))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#土日フラグ(day_of_week_1)と、休日前(holi_2)フラグを追加\n",
    "data['hol']['day_of_week_1']= data['hol']['day_of_week'].replace(['Saturday', 'Sunday','Monday','Tuesday','Wednesday','Thursday','Friday'],['1', '1','0','0','0','0','0']).astype('int')\n",
    "data['hol']['holi_2'] = data['hol'][['holiday_flg', 'day_of_week_1']].sum(axis = 1)\n",
    "data['hol']['holi_2'] = data['hol']['holi_2'].apply( lambda x: 0 if x < 1 else 1 )\n",
    "data['hol']['holi_2'] = data['hol']['holi_2'].shift(-1)\n",
    "data['hol']['holi_2'] = data['hol']['holi_2'].fillna(1)\n",
    "data['hol']['holi_2'] = data['hol']['holi_2'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>day_of_week_1</th>\n",
       "      <th>holi_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date day_of_week  holiday_flg  day_of_week_1  holi_2\n",
       "0  2016-01-01      Friday            1              0       1\n",
       "1  2016-01-02    Saturday            1              1       1\n",
       "2  2016-01-03      Sunday            1              1       0\n",
       "3  2016-01-04      Monday            0              0       0\n",
       "4  2016-01-05     Tuesday            0              0       0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hol'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "train = pd.merge(data['tra'], data['hol'], how ='left', on = ['visit_date'])\n",
    "test = pd.merge(data['tes'], data['hol'], how ='left', on = ['visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#曜日と月でmerge\n",
    "#train = pd.merge(train, stores, how ='left', on = ['air_store_id', 'dow','month'])\n",
    "train = pd.merge(train, stores, how ='inner', on = ['air_store_id', 'dow','month'])\n",
    "test = pd.merge(test, stores, how ='left', on = ['air_store_id', 'dow','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ID×休日前でのvisitorsの平均、中央値等を追加\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].min().rename(columns = {'visitors':'h_min_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'h_mean_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].median().rename(columns = {'visitors':'h_median_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].max().rename(columns = {'visitors':'h_max_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].count().rename(columns = {'visitors':'h_count_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>day_of_week_1</th>\n",
       "      <th>holi_2</th>\n",
       "      <th>...</th>\n",
       "      <th>air_area_name7</th>\n",
       "      <th>air_genre_name8</th>\n",
       "      <th>air_area_name8</th>\n",
       "      <th>air_genre_name9</th>\n",
       "      <th>air_area_name9</th>\n",
       "      <th>h_min_visitors</th>\n",
       "      <th>h_mean_visitors</th>\n",
       "      <th>h_median_visitors</th>\n",
       "      <th>h_max_visitors</th>\n",
       "      <th>h_count_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>air_c7d30ab0e07f31d5</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>14.5</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>air_c7d30ab0e07f31d5</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>14.5</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>air_c7d30ab0e07f31d5</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>14.5</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>air_c7d30ab0e07f31d5</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>14.5</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>air_24e8414b9b07decb</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              air_store_id  visit_date  visitors  dow  year  month  \\\n",
       "6735  air_c7d30ab0e07f31d5  2016-05-06         8    4  2016      5   \n",
       "6736  air_c7d30ab0e07f31d5  2016-05-13        20    4  2016      5   \n",
       "6737  air_c7d30ab0e07f31d5  2016-05-07        11    5  2016      5   \n",
       "6738  air_c7d30ab0e07f31d5  2016-05-14        10    5  2016      5   \n",
       "6739  air_24e8414b9b07decb  2017-04-22         5    5  2017      4   \n",
       "\n",
       "      day_of_week  holiday_flg  day_of_week_1  holi_2        ...         \\\n",
       "6735            0            0              0       1        ...          \n",
       "6736            0            0              0       1        ...          \n",
       "6737            2            0              1       1        ...          \n",
       "6738            2            0              1       1        ...          \n",
       "6739            2            0              1       1        ...          \n",
       "\n",
       "      air_area_name7  air_genre_name8  air_area_name8  air_genre_name9  \\\n",
       "6735               0                0               0                0   \n",
       "6736               0                0               0                0   \n",
       "6737               0                0               0                0   \n",
       "6738               0                0               0                0   \n",
       "6739               0                0               0                0   \n",
       "\n",
       "      air_area_name9  h_min_visitors  h_mean_visitors  h_median_visitors  \\\n",
       "6735               0               8        15.083333               14.5   \n",
       "6736               0               8        15.083333               14.5   \n",
       "6737               0               8        15.083333               14.5   \n",
       "6738               0               8        15.083333               14.5   \n",
       "6739               0               5         5.000000                5.0   \n",
       "\n",
       "      h_max_visitors  h_count_visitors  \n",
       "6735              24                12  \n",
       "6736              24                12  \n",
       "6737              24                12  \n",
       "6738              24                12  \n",
       "6739               5                 1  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine = [train, test]\n",
    "#gw_list = ['2017-04-22','2017-04-21','2017-04-20','2017-04-19','2017-04-18','2017-04-17','2017-04-16','2017-04-15','2017-04-14','2017-04-13','2017-04-12','2017-04-11','2017-04-10','2017-04-09','2017-04-08']\n",
    "#post_gw_list=[]\n",
    "#train['gw_flg'] = 0\n",
    "#train['post_gw_flg'] = 0\n",
    "#test['gw_flg'] = 0\n",
    "#test['post_gw_flg'] = 0\n",
    "#update_gw_list = [[\"0\" for i in range(3)] for j in range(len(gw_list))]\n",
    "#update_post_gw_list = [[\"0\" for i in range(3)] for j in range(len(post_gw_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from datetime import date\n",
    "#for index, gw_date in enumerate(gw_list):\n",
    "#    temp_list = gw_date.split(\"-\")\n",
    "#    for col_i, temp_figure in enumerate(temp_list):\n",
    "#        update_gw_list[index][col_i]=int(temp_figure)\n",
    "#        \n",
    "#    #print(\"{}  {}  {}\".format(update_list[index][0],update_list[index][1],update_list[index][2]))\n",
    "#    #\n",
    "#for index, gw_date in enumerate(post_gw_list):\n",
    "#    temp_list = gw_date.split(\"-\")\n",
    "#    for col_i, temp_figure in enumerate(temp_list):\n",
    "#        update_post_gw_list[index][col_i]=int(temp_figure)\n",
    "#\n",
    "#for dataset in combine:\n",
    "#    for index in range(len(update_gw_list)):\n",
    "#        dataset.loc[dataset.visit_date == date(update_gw_list[index][0],update_gw_list[index][1],update_gw_list[index][2]), 'gw_flg'] = 1\n",
    "#        \n",
    "#for dataset in combine:\n",
    "#    for index in range(len(update_post_gw_list)):\n",
    "#        dataset.loc[dataset.visit_date == date(update_post_gw_list[index][0],update_post_gw_list[index][1],update_post_gw_list[index][2]), 'post_gw_flg'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tmp = train.groupby(['air_store_id','gw_flg'], as_index = False)['visitors'].min().rename(columns = {'visitors':'gw_min_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#tmp = train.groupby(['air_store_id','gw_flg'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'gw_mean_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#tmp = train.groupby(['air_store_id','gw_flg'], as_index = False)['visitors'].median().rename(columns = {'visitors':'gw_median_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#tmp = train.groupby(['air_store_id','gw_flg'], as_index = False)['visitors'].max().rename(columns = {'visitors':'gw_max_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#tmp = train.groupby(['air_store_id','gw_flg'], as_index = False)['visitors'].count().rename(columns = {'visitors':'gw_count_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','gw_flg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tmp = train.groupby(['air_store_id','post_gw_flg'], as_index = False)['visitors'].min().rename(columns = {'visitors':'pgw_min_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#tmp = train.groupby(['air_store_id','post_gw_flg'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'pgw_mean_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#tmp = train.groupby(['air_store_id','post_gw_flg'], as_index = False)['visitors'].median().rename(columns = {'visitors':'pgw_median_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#tmp = train.groupby(['air_store_id','post_gw_flg'], as_index = False)['visitors'].max().rename(columns = {'visitors':'pgw_max_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#tmp = train.groupby(['air_store_id','post_gw_flg'], as_index = False)['visitors'].count().rename(columns = {'visitors':'pgw_count_visitors'})\n",
    "#train = pd.merge(train, tmp, how ='left', on = ['air_store_id','post_gw_flg'])\n",
    "#test = pd.merge(test, tmp, how ='left', on = ['air_store_id','post_gw_flg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y'])/2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y'])/2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2']= lbl.fit_transform(test['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date', 'visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#指数移動平均の追加。これはなくても良いかも\n",
    "#https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/46179#266344\n",
    "#def calc_shifted_ewm(series, alpha, adjust=True):\n",
    "#    return series.shift().ewm(alpha=alpha, adjust=adjust).mean()\n",
    "\n",
    "#train['ewm'] = train.groupby(['air_store_id', 'dow']).apply(lambda g: calc_shifted_ewm(g['visitors'], 0.1)).sort_index(level=['air_store_id']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#以下、気象データの追加\n",
    "df_air_store_weather_station = pd.read_csv('./air_store_info_with_nearest_active_station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['air_store_id', 'station_id', 'station_latitude', 'station_longitude', 'station_vincenty', 'station_great_circle']\n",
    "all_data = pd.merge(all_data, df_air_store_weather_station[cols], on='air_store_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine = all_data\n",
    "filenames = []\n",
    "df_weather = None\n",
    "for station_id in combine['station_id'].unique():\n",
    "    fn = f\"/Users/suzukishinji/kaggle/recluit/1-1-16_5-31-17_Weather/{station_id}.csv\"\n",
    "    if not fn in filenames:\n",
    "        df = pd.read_csv(fn)\n",
    "        df['station_id'] = station_id\n",
    "        if df_weather is None:\n",
    "            df_weather = df\n",
    "        else:\n",
    "            df_weather = pd.concat([df_weather, df])\n",
    "        del df\n",
    "\n",
    "        filenames.append(fn)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#欠損値を平均で穴埋め（median, ffillで試すも特に差は出なかった）\n",
    "df_weather = df_weather.fillna(df_weather.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_weather = df_weather.rename(columns={'calendar_date': 'visit_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_weather['visit_date'] = pd.to_datetime(df_weather['visit_date'])\n",
    "df_weather['visit_date'] = df_weather['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#なんとなく対数化\n",
    "df_weather['precipitation'] = np.log1p(df_weather['precipitation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使いそうなデータだけ結合（その他の気象データは試していません。特に意味はなし）\n",
    "cols = ['station_id', \n",
    "    'visit_date', \n",
    "    'precipitation', \n",
    "    'hours_sunlight',\n",
    "    'avg_temperature',\n",
    "    'high_temperature',\n",
    "    'low_temperature']\n",
    "\n",
    "combine = pd.merge(combine, df_weather[cols], on=['station_id', 'visit_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#降水量をカテゴリ化\n",
    "def simplify_pre(df):\n",
    "    df.precipitation = df.precipitation.fillna(0)\n",
    "    bins = ( -1, 0.01, 2,  5)\n",
    "    group_names = ['1', '2', '3']\n",
    "    categories = pd.cut(df.precipitation, bins, labels=group_names)\n",
    "    df.precipitation = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine = simplify_pre(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#不要そうなデータを削除\n",
    "drop_col =['station_id', 'station_latitude','station_longitude','station_vincenty', 'station_great_circle','hours_sunlight','high_temperature','low_temperature']\n",
    "all_data = all_data.drop(drop_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ID×降水量で平均、中央値等を追加\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].min().rename(columns = {'visitors':'p_min_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'p_mean_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].median().rename(columns = {'visitors':'p_median_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation',])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].max().rename(columns = {'visitors':'p_max_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].count().rename(columns = {'visitors':'p_count_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#countをLabel Encoder化。なんとなく試してみたら結果が良かった。\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['count_visitors'] = lbl.fit_transform(train['count_observations']) \n",
    "test['count_visitors']= lbl.fit_transform(test['count_observations'])\n",
    "train['m_count_visitors'] = lbl.fit_transform(train['m_count_visitors'])\n",
    "test['m_count_visitors']= lbl.fit_transform(test['m_count_visitors'])\n",
    "train['h_count_reserves'] = lbl.fit_transform(train['h_count_visitors'])\n",
    "test['h_count_reserves']= lbl.fit_transform(test['h_count_visitors'])\n",
    "train['p_count_visitors'] = lbl.fit_transform(train['p_count_visitors'])\n",
    "test['p_count_visitors']= lbl.fit_transform(test['p_count_visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value_col = ['holiday_flg','min_visitors','mean_visitors','median_visitors','max_visitors','count_observations',\n",
    "'rs1_x','rv1_x','rs2_x','rv2_x','rs1_y','rv1_y','rs2_y','rv2_y','total_reserv_sum','total_reserv_mean',\n",
    "'total_reserv_dt_diff_mean','date_int','var_max_lat','var_max_long','lon_plus_lat']\n",
    "\n",
    "nn_col = value_col + ['dow', 'year', 'month', 'air_store_id2', 'air_area_name', 'air_genre_name',\n",
    "'air_area_name0', 'air_area_name1', 'air_area_name2', 'air_area_name3', 'air_area_name4',\n",
    "'air_area_name5', 'air_area_name6', 'air_genre_name0', 'air_genre_name1',\n",
    "'air_genre_name2', 'air_genre_name3', 'air_genre_name4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18062 entries, 0 to 18061\n",
      "Data columns (total 76 columns):\n",
      "air_area_name                18062 non-null int64\n",
      "air_area_name0               18062 non-null int64\n",
      "air_area_name1               18062 non-null int64\n",
      "air_area_name2               18062 non-null int64\n",
      "air_area_name3               18062 non-null int64\n",
      "air_area_name4               18062 non-null int64\n",
      "air_area_name5               18062 non-null int64\n",
      "air_area_name6               18062 non-null int64\n",
      "air_area_name7               18062 non-null int64\n",
      "air_area_name8               18062 non-null int64\n",
      "air_area_name9               18062 non-null int64\n",
      "air_genre_name               18062 non-null int64\n",
      "air_genre_name0              18062 non-null int64\n",
      "air_genre_name1              18062 non-null int64\n",
      "air_genre_name2              18062 non-null int64\n",
      "air_genre_name3              18062 non-null int64\n",
      "air_genre_name4              18062 non-null int64\n",
      "air_genre_name5              18062 non-null int64\n",
      "air_genre_name6              18062 non-null int64\n",
      "air_genre_name7              18062 non-null int64\n",
      "air_genre_name8              18062 non-null int64\n",
      "air_genre_name9              18062 non-null int64\n",
      "air_store_id                 18062 non-null object\n",
      "air_store_id2                18062 non-null int64\n",
      "count_observations           18062 non-null float64\n",
      "date_int                     18062 non-null int64\n",
      "day_of_week                  18062 non-null int64\n",
      "day_of_week_1                18062 non-null int64\n",
      "dow                          18062 non-null int64\n",
      "genre_in_area                18062 non-null int64\n",
      "h_count_visitors             18062 non-null float64\n",
      "h_max_visitors               18062 non-null float64\n",
      "h_mean_visitors              18062 non-null float64\n",
      "h_median_visitors            18062 non-null float64\n",
      "h_min_visitors               18062 non-null float64\n",
      "holi_2                       18062 non-null int64\n",
      "holiday_flg                  18062 non-null int64\n",
      "id                           18062 non-null object\n",
      "latitude                     18062 non-null float64\n",
      "lon_plus_lat                 18062 non-null float64\n",
      "longitude                    18062 non-null float64\n",
      "m_count_visitors             18062 non-null int64\n",
      "m_max_visitors               18062 non-null float64\n",
      "m_mean_visitors              18062 non-null float64\n",
      "m_median_visitors            18062 non-null float64\n",
      "m_min_visitors               18062 non-null float64\n",
      "max_visitors                 18062 non-null float64\n",
      "mean_visitors                18062 non-null float64\n",
      "median_visitors              18062 non-null float64\n",
      "min_visitors                 18062 non-null float64\n",
      "month                        18062 non-null int64\n",
      "rs1_x                        18062 non-null float64\n",
      "rs1_y                        18062 non-null float64\n",
      "rs2_x                        18062 non-null float64\n",
      "rs2_y                        18062 non-null float64\n",
      "rv1_x                        18062 non-null float64\n",
      "rv1_y                        18062 non-null float64\n",
      "rv2_x                        18062 non-null float64\n",
      "rv2_y                        18062 non-null float64\n",
      "total_reserv_dt_diff_mean    18062 non-null float64\n",
      "total_reserv_mean            18062 non-null float64\n",
      "total_reserv_sum             18062 non-null float64\n",
      "var_max_lat                  18062 non-null float64\n",
      "var_max_long                 18062 non-null float64\n",
      "visit_date                   18062 non-null object\n",
      "visitors                     18062 non-null int64\n",
      "year                         18062 non-null int64\n",
      "precipitation                18062 non-null category\n",
      "avg_temperature              18062 non-null float64\n",
      "p_min_visitors               9858 non-null float64\n",
      "p_mean_visitors              9858 non-null float64\n",
      "p_median_visitors            9858 non-null float64\n",
      "p_max_visitors               9858 non-null float64\n",
      "p_count_visitors             18062 non-null int64\n",
      "count_visitors               18062 non-null int64\n",
      "h_count_reserves             18062 non-null int64\n",
      "dtypes: category(1), float64(35), int64(37), object(3)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6740 entries, 0 to 6739\n",
      "Data columns (total 76 columns):\n",
      "air_area_name                6740 non-null int64\n",
      "air_area_name0               6740 non-null int64\n",
      "air_area_name1               6740 non-null int64\n",
      "air_area_name2               6740 non-null int64\n",
      "air_area_name3               6740 non-null int64\n",
      "air_area_name4               6740 non-null int64\n",
      "air_area_name5               6740 non-null int64\n",
      "air_area_name6               6740 non-null int64\n",
      "air_area_name7               6740 non-null int64\n",
      "air_area_name8               6740 non-null int64\n",
      "air_area_name9               6740 non-null int64\n",
      "air_genre_name               6740 non-null int64\n",
      "air_genre_name0              6740 non-null int64\n",
      "air_genre_name1              6740 non-null int64\n",
      "air_genre_name2              6740 non-null int64\n",
      "air_genre_name3              6740 non-null int64\n",
      "air_genre_name4              6740 non-null int64\n",
      "air_genre_name5              6740 non-null int64\n",
      "air_genre_name6              6740 non-null int64\n",
      "air_genre_name7              6740 non-null int64\n",
      "air_genre_name8              6740 non-null int64\n",
      "air_genre_name9              6740 non-null int64\n",
      "air_store_id                 6740 non-null object\n",
      "air_store_id2                6740 non-null int64\n",
      "count_observations           6740 non-null float64\n",
      "date_int                     6740 non-null int64\n",
      "day_of_week                  6740 non-null int64\n",
      "day_of_week_1                6740 non-null int64\n",
      "dow                          6740 non-null int64\n",
      "genre_in_area                6740 non-null int64\n",
      "h_count_visitors             6740 non-null float64\n",
      "h_max_visitors               6740 non-null float64\n",
      "h_mean_visitors              6740 non-null float64\n",
      "h_median_visitors            6740 non-null float64\n",
      "h_min_visitors               6740 non-null float64\n",
      "holi_2                       6740 non-null int64\n",
      "holiday_flg                  6740 non-null int64\n",
      "id                           6740 non-null object\n",
      "latitude                     6740 non-null float64\n",
      "lon_plus_lat                 6740 non-null float64\n",
      "longitude                    6740 non-null float64\n",
      "m_count_visitors             6740 non-null int64\n",
      "m_max_visitors               6740 non-null float64\n",
      "m_mean_visitors              6740 non-null float64\n",
      "m_median_visitors            6740 non-null float64\n",
      "m_min_visitors               6740 non-null float64\n",
      "max_visitors                 6740 non-null float64\n",
      "mean_visitors                6740 non-null float64\n",
      "median_visitors              6740 non-null float64\n",
      "min_visitors                 6740 non-null float64\n",
      "month                        6740 non-null int64\n",
      "rs1_x                        6740 non-null float64\n",
      "rs1_y                        6740 non-null float64\n",
      "rs2_x                        6740 non-null float64\n",
      "rs2_y                        6740 non-null float64\n",
      "rv1_x                        6740 non-null float64\n",
      "rv1_y                        6740 non-null float64\n",
      "rv2_x                        6740 non-null float64\n",
      "rv2_y                        6740 non-null float64\n",
      "total_reserv_dt_diff_mean    6740 non-null float64\n",
      "total_reserv_mean            6740 non-null float64\n",
      "total_reserv_sum             6740 non-null float64\n",
      "var_max_lat                  6740 non-null float64\n",
      "var_max_long                 6740 non-null float64\n",
      "visit_date                   6740 non-null object\n",
      "visitors                     6740 non-null int64\n",
      "year                         6740 non-null int64\n",
      "precipitation                6740 non-null category\n",
      "avg_temperature              6740 non-null float64\n",
      "p_min_visitors               6740 non-null float64\n",
      "p_mean_visitors              6740 non-null float64\n",
      "p_median_visitors            6740 non-null float64\n",
      "p_max_visitors               6740 non-null float64\n",
      "p_count_visitors             6740 non-null int64\n",
      "count_visitors               6740 non-null int64\n",
      "h_count_reserves             6740 non-null int64\n",
      "dtypes: category(1), float64(35), int64(37), object(3)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data prepared\n"
     ]
    }
   ],
   "source": [
    "X = train.copy()\n",
    "X_test = test[nn_col].copy()\n",
    "\n",
    "value_scaler = preprocessing.MinMaxScaler()\n",
    "for vcol in value_col:\n",
    "    X[vcol] = value_scaler.fit_transform(X[vcol].values.astype(np.float64).reshape(-1, 1))\n",
    "    X_test[vcol] = value_scaler.transform(X_test[vcol].values.astype(np.float64).reshape(-1, 1))\n",
    "\n",
    "X_train = list(X[nn_col].T.as_matrix())\n",
    "Y_train = np.log1p(X['visitors']).values\n",
    "nn_train = [X_train, Y_train]\n",
    "nn_test = [list(X_test[nn_col].T.as_matrix())]\n",
    "print(\"Train and test data prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nn_complete_model(train, hidden1_neurons=35, hidden2_neurons=15):\n",
    "    K.clear_session()\n",
    "\n",
    "    air_store_id = Input(shape=(1,), dtype='int32', name='air_store_id')\n",
    "    air_store_id_emb = Embedding(len(train['air_store_id2'].unique()) + 1, 15, input_shape=(1,),\n",
    "                                 name='air_store_id_emb')(air_store_id)\n",
    "    air_store_id_emb = keras.layers.Flatten(name='air_store_id_emb_flatten')(air_store_id_emb)\n",
    "\n",
    "    dow = Input(shape=(1,), dtype='int32', name='dow')\n",
    "    dow_emb = Embedding(8, 3, input_shape=(1,), name='dow_emb')(dow)\n",
    "    dow_emb = keras.layers.Flatten(name='dow_emb_flatten')(dow_emb)\n",
    "\n",
    "    month = Input(shape=(1,), dtype='int32', name='month')\n",
    "    month_emb = Embedding(13, 3, input_shape=(1,), name='month_emb')(month)\n",
    "    month_emb = keras.layers.Flatten(name='month_emb_flatten')(month_emb)\n",
    "\n",
    "    air_area_name, air_genre_name = [], []\n",
    "    air_area_name_emb, air_genre_name_emb = [], []\n",
    "    for i in range(7):\n",
    "        area_name_col = 'air_area_name' + str(i)\n",
    "        air_area_name.append(Input(shape=(1,), dtype='int32', name=area_name_col))\n",
    "        tmp = Embedding(len(train[area_name_col].unique()), 3, input_shape=(1,),\n",
    "                        name=area_name_col + '_emb')(air_area_name[-1])\n",
    "        tmp = keras.layers.Flatten(name=area_name_col + '_emb_flatten')(tmp)\n",
    "        air_area_name_emb.append(tmp)\n",
    "\n",
    "        if i > 4:\n",
    "            continue\n",
    "        area_genre_col = 'air_genre_name' + str(i)\n",
    "        air_genre_name.append(Input(shape=(1,), dtype='int32', name=area_genre_col))\n",
    "        tmp = Embedding(len(train[area_genre_col].unique()), 3, input_shape=(1,),\n",
    "                        name=area_genre_col + '_emb')(air_genre_name[-1])\n",
    "        tmp = keras.layers.Flatten(name=area_genre_col + '_emb_flatten')(tmp)\n",
    "        air_genre_name_emb.append(tmp)\n",
    "\n",
    "    air_genre_name_emb = keras.layers.concatenate(air_genre_name_emb)\n",
    "    air_genre_name_emb = Dense(4, activation='sigmoid', name='final_air_genre_emb')(air_genre_name_emb)\n",
    "\n",
    "    air_area_name_emb = keras.layers.concatenate(air_area_name_emb)\n",
    "    air_area_name_emb = Dense(4, activation='sigmoid', name='final_air_area_emb')(air_area_name_emb)\n",
    "    \n",
    "    air_area_code = Input(shape=(1,), dtype='int32', name='air_area_code')\n",
    "    air_area_code_emb = Embedding(len(train['air_area_name'].unique()), 8, input_shape=(1,), name='air_area_code_emb')(air_area_code)\n",
    "    air_area_code_emb = keras.layers.Flatten(name='air_area_code_emb_flatten')(air_area_code_emb)\n",
    "    \n",
    "    air_genre_code = Input(shape=(1,), dtype='int32', name='air_genre_code')\n",
    "    air_genre_code_emb = Embedding(len(train['air_genre_name'].unique()), 5, input_shape=(1,),\n",
    "                                   name='air_genre_code_emb')(air_genre_code)\n",
    "    air_genre_code_emb = keras.layers.Flatten(name='air_genre_code_emb_flatten')(air_genre_code_emb)\n",
    "\n",
    "    \n",
    "    holiday_flg = Input(shape=(1,), dtype='float32', name='holiday_flg')\n",
    "    year = Input(shape=(1,), dtype='float32', name='year')\n",
    "    min_visitors = Input(shape=(1,), dtype='float32', name='min_visitors')\n",
    "    mean_visitors = Input(shape=(1,), dtype='float32', name='mean_visitors')\n",
    "    median_visitors = Input(shape=(1,), dtype='float32', name='median_visitors')\n",
    "    max_visitors = Input(shape=(1,), dtype='float32', name='max_visitors')\n",
    "    count_observations = Input(shape=(1,), dtype='float32', name='count_observations')\n",
    "    rs1_x = Input(shape=(1,), dtype='float32', name='rs1_x')\n",
    "    rv1_x = Input(shape=(1,), dtype='float32', name='rv1_x')\n",
    "    rs2_x = Input(shape=(1,), dtype='float32', name='rs2_x')\n",
    "    rv2_x = Input(shape=(1,), dtype='float32', name='rv2_x')\n",
    "    rs1_y = Input(shape=(1,), dtype='float32', name='rs1_y')\n",
    "    rv1_y = Input(shape=(1,), dtype='float32', name='rv1_y')\n",
    "    rs2_y = Input(shape=(1,), dtype='float32', name='rs2_y')\n",
    "    rv2_y = Input(shape=(1,), dtype='float32', name='rv2_y')\n",
    "    total_reserv_sum = Input(shape=(1,), dtype='float32', name='total_reserv_sum')\n",
    "    total_reserv_mean = Input(shape=(1,), dtype='float32', name='total_reserv_mean')\n",
    "    total_reserv_dt_diff_mean = Input(shape=(1,), dtype='float32', name='total_reserv_dt_diff_mean')\n",
    "    date_int = Input(shape=(1,), dtype='float32', name='date_int')\n",
    "    var_max_lat = Input(shape=(1,), dtype='float32', name='var_max_lat')\n",
    "    var_max_long = Input(shape=(1,), dtype='float32', name='var_max_long')\n",
    "    lon_plus_lat = Input(shape=(1,), dtype='float32', name='lon_plus_lat')\n",
    "\n",
    "    date_emb = keras.layers.concatenate([dow_emb, month_emb, year, holiday_flg])\n",
    "    date_emb = Dense(5, activation='sigmoid', name='date_merged_emb')(date_emb)\n",
    "\n",
    "    cat_layer = keras.layers.concatenate([holiday_flg, min_visitors, mean_visitors,\n",
    "                    median_visitors, max_visitors, count_observations, rs1_x, rv1_x,\n",
    "                    rs2_x, rv2_x, rs1_y, rv1_y, rs2_y, rv2_y,\n",
    "                    total_reserv_sum, total_reserv_mean, total_reserv_dt_diff_mean,\n",
    "                    date_int, var_max_lat, var_max_long, lon_plus_lat,\n",
    "                    date_emb, air_area_name_emb, air_genre_name_emb,\n",
    "                    air_area_code_emb, air_genre_code_emb, air_store_id_emb])\n",
    "\n",
    "    m = Dense(hidden1_neurons, name='hidden1',\n",
    "             kernel_initializer=keras.initializers.RandomNormal(mean=0.0,\n",
    "                            stddev=0.05, seed=None))(cat_layer)\n",
    "    m = keras.layers.LeakyReLU(alpha=0.2)(m)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    \n",
    "    m1 = Dense(hidden2_neurons, name='sub1')(m)\n",
    "    m1 = keras.layers.LeakyReLU(alpha=0.2)(m1)\n",
    "    m = Dense(1, activation='relu')(m1)\n",
    "\n",
    "    inp_ten = [\n",
    "        holiday_flg, min_visitors, mean_visitors, median_visitors, max_visitors, count_observations,\n",
    "        rs1_x, rv1_x, rs2_x, rv2_x, rs1_y, rv1_y, rs2_y, rv2_y, total_reserv_sum, total_reserv_mean,\n",
    "        total_reserv_dt_diff_mean, date_int, var_max_lat, var_max_long, lon_plus_lat,\n",
    "        dow, year, month, air_store_id, air_area_code, air_genre_code\n",
    "    ]\n",
    "    inp_ten += air_area_name\n",
    "    inp_ten += air_genre_name\n",
    "    model = keras.Model(inp_ten, m)\n",
    "    model.compile(loss='mse', optimizer='rmsprop', metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = get_nn_complete_model(train, hidden2_neurons=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nn_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5729 samples, validate on 1011 samples\n",
      "Epoch 1/3\n",
      "5729/5729 [==============================] - 2s 310us/step - loss: 5.4341 - acc: 0.0000e+00 - val_loss: 5.9333 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "5729/5729 [==============================] - 0s 34us/step - loss: 2.0983 - acc: 0.0000e+00 - val_loss: 2.2921 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "5729/5729 [==============================] - 0s 34us/step - loss: 1.4466 - acc: 0.0000e+00 - val_loss: 1.6116 - val_acc: 0.0000e+00\n",
      "Train on 5729 samples, validate on 1011 samples\n",
      "Epoch 1/3\n",
      "5729/5729 [==============================] - 0s 36us/step - loss: 0.2055 - acc: 0.0000e+00 - val_loss: 0.2722 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "5729/5729 [==============================] - 0s 37us/step - loss: 0.2000 - acc: 0.0000e+00 - val_loss: 0.3845 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "5729/5729 [==============================] - 0s 34us/step - loss: 0.1965 - acc: 0.0000e+00 - val_loss: 0.3925 - val_acc: 0.0000e+00\n",
      "Train on 5729 samples, validate on 1011 samples\n",
      "Epoch 1/3\n",
      "5729/5729 [==============================] - 0s 34us/step - loss: 0.1833 - acc: 0.0000e+00 - val_loss: 0.2362 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "5729/5729 [==============================] - 0s 35us/step - loss: 0.1807 - acc: 0.0000e+00 - val_loss: 0.2324 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "5729/5729 [==============================] - 0s 40us/step - loss: 0.1739 - acc: 0.0000e+00 - val_loss: 0.2329 - val_acc: 0.0000e+00\n",
      "Train on 5729 samples, validate on 1011 samples\n",
      "Epoch 1/3\n",
      "5729/5729 [==============================] - 0s 36us/step - loss: 0.1718 - acc: 0.0000e+00 - val_loss: 0.2079 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "5729/5729 [==============================] - 0s 41us/step - loss: 0.1751 - acc: 0.0000e+00 - val_loss: 0.2075 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "5729/5729 [==============================] - 0s 36us/step - loss: 0.1693 - acc: 0.0000e+00 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Train on 5729 samples, validate on 1011 samples\n",
      "Epoch 1/3\n",
      "5729/5729 [==============================] - 0s 32us/step - loss: 0.1699 - acc: 0.0000e+00 - val_loss: 0.2681 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "5729/5729 [==============================] - 0s 39us/step - loss: 0.1631 - acc: 0.0000e+00 - val_loss: 0.2076 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "5729/5729 [==============================] - 0s 39us/step - loss: 0.1580 - acc: 0.0000e+00 - val_loss: 0.2634 - val_acc: 0.0000e+00\n",
      "Model4 trained\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model4.fit(nn_train[0], nn_train[1], epochs=3, verbose=1,\n",
    "        batch_size=256, shuffle=True, validation_split=0.15)\n",
    "    model4.fit(nn_train[0], nn_train[1], epochs=8, verbose=0,\n",
    "        batch_size=256, shuffle=True)\n",
    "print(\"Model4 trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds5 = pd.Series(model4.predict(nn_train[0]).reshape(-1)).clip(0, 6.8).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE NeuralNetwork:  0.4442205034375069\n"
     ]
    }
   ],
   "source": [
    "print('RMSE NeuralNetwork: ', RMSLE(np.log1p(train['visitors'].values), preds5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[14,0] = 789 is not in [0, 789)\n\t [[Node: air_store_id_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](air_store_id_emb/embeddings/read, _arg_air_store_id_0_14)]]\n\nCaused by op 'air_store_id_emb/Gather', defined at:\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-240-c994cbb7c4a6>\", line 1, in <module>\n    model4 = get_nn_complete_model(train, hidden2_neurons=12)\n  File \"<ipython-input-238-9d1612531d92>\", line 6, in get_nn_complete_model\n    name='air_store_id_emb')(air_store_id)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2486, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1834, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[14,0] = 789 is not in [0, 789)\n\t [[Node: air_store_id_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](air_store_id_emb/embeddings/read, _arg_air_store_id_0_14)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[14,0] = 789 is not in [0, 789)\n\t [[Node: air_store_id_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](air_store_id_emb/embeddings/read, _arg_air_store_id_0_14)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-5eab4e6e01c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1798\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1800\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[14,0] = 789 is not in [0, 789)\n\t [[Node: air_store_id_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](air_store_id_emb/embeddings/read, _arg_air_store_id_0_14)]]\n\nCaused by op 'air_store_id_emb/Gather', defined at:\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-240-c994cbb7c4a6>\", line 1, in <module>\n    model4 = get_nn_complete_model(train, hidden2_neurons=12)\n  File \"<ipython-input-238-9d1612531d92>\", line 6, in get_nn_complete_model\n    name='air_store_id_emb')(air_store_id)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2486, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1834, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/suzukishinji/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[14,0] = 789 is not in [0, 789)\n\t [[Node: air_store_id_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](air_store_id_emb/embeddings/read, _arg_air_store_id_0_14)]]\n"
     ]
    }
   ],
   "source": [
    "preds5 = pd.Series(model4.predict(nn_test[0]).reshape(-1)).clip(0, 6.8).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#以下、各モデルをCVで4回\n",
    "X = train[col]\n",
    "y = pd.DataFrame()\n",
    "y['visitors'] = np.log1p(train['visitors'].values)\n",
    "testes =test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "X.sort_index(axis=1, inplace=True)\n",
    "y.sort_index(axis=1,inplace=True)\n",
    "testes.sort_index(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_hideout, y, y_hideout = model_selection.train_test_split(X, y, test_size = 0.13, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "kf = model_selection.KFold(n_splits = K, random_state = 1, shuffle = True)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.1, \n",
    "        'n_estimators': 375,\n",
    "         'max_depth' : 6,\n",
    "         'min_samples_leaf': 2}\n",
    "model1 = ensemble.GradientBoostingRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started CV at  2018-02-06 14:52:57.381989\n",
      "\n",
      "Fold  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE GBM Regressor, validation set, fold  0 :  0.46426761028114893\n",
      "RMSLE GBM Regressor, hideout set, fold  0 :  0.4561170460023926\n",
      "Prediction length on validation set, GBM Regressor, fold  0 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  0 :  18062\n",
      "\n",
      "Fold  1\n",
      "RMSLE GBM Regressor, validation set, fold  1 :  0.4393993123459226\n",
      "RMSLE GBM Regressor, hideout set, fold  1 :  0.4630895409882873\n",
      "Prediction length on validation set, GBM Regressor, fold  1 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  1 :  18062\n",
      "\n",
      "Fold  2\n",
      "RMSLE GBM Regressor, validation set, fold  2 :  0.44802343251179744\n",
      "RMSLE GBM Regressor, hideout set, fold  2 :  0.45532103180991157\n",
      "Prediction length on validation set, GBM Regressor, fold  2 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  2 :  18062\n",
      "\n",
      "Fold  3\n",
      "RMSLE GBM Regressor, validation set, fold  3 :  0.46085482548447454\n",
      "RMSLE GBM Regressor, hideout set, fold  3 :  0.47172054406435243\n",
      "Prediction length on validation set, GBM Regressor, fold  3 :  1465\n",
      "Prediction length on test set, GBM Regressor, fold  3 :  18062\n",
      "Finished CV at  2018-02-06 14:53:32.565038\n",
      "Finished average test set predictions at  2018-02-06 14:53:32.565415\n"
     ]
    }
   ],
   "source": [
    "print(\"Started CV at \", dt.datetime.now())\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n",
    "    X_test = testes\n",
    "    print(\"\\nFold \", i)\n",
    "\n",
    "    fit_model = model1.fit(X_train, y_train)\n",
    "    pred = model1.predict(X_valid)\n",
    "    print('RMSLE GBM Regressor, validation set, fold ', i, ': ', RMSLE(y_valid, pred))\n",
    "\n",
    "    pred_hideout = model1.predict(X_hideout)\n",
    "    print('RMSLE GBM Regressor, hideout set, fold ', i, ': ', RMSLE(y_hideout, pred_hideout))\n",
    "    print('Prediction length on validation set, GBM Regressor, fold ', i, ': ', len(pred))\n",
    "    # Accumulate test set predictions\n",
    "\n",
    "    pred = model1.predict(X_test)\n",
    "    print('Prediction length on test set, GBM Regressor, fold ', i, ': ', len(pred))\n",
    "    y_test_pred1 += pred\n",
    "\n",
    "    del X_test, X_train, X_valid, y_train\n",
    "\n",
    "print(\"Finished CV at \", dt.datetime.now())\n",
    "\n",
    "y_test_pred1 /= K  # Average test set predictions\n",
    "print(\"Finished average test set predictions at \", dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'n_jobs': -1,\n",
    "        'n_neighbors': 4}\n",
    "\n",
    "model2 = neighbors.KNeighborsRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started CV at  2018-02-06 14:53:32.612382\n",
      "\n",
      "Fold  0\n",
      "RMSLE GBM Regressor, validation set, fold  0 :  0.5911623261448579\n",
      "RMSLE GBM Regressor, hideout set, fold  0 :  0.5873523668889227\n",
      "Prediction length on validation set, GBM Regressor, fold  0 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  0 :  18062\n",
      "\n",
      "Fold  1\n",
      "RMSLE GBM Regressor, validation set, fold  1 :  0.5632223617043908\n",
      "RMSLE GBM Regressor, hideout set, fold  1 :  0.5872864380052101\n",
      "Prediction length on validation set, GBM Regressor, fold  1 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  1 :  18062\n",
      "\n",
      "Fold  2\n",
      "RMSLE GBM Regressor, validation set, fold  2 :  0.5760207511509177\n",
      "RMSLE GBM Regressor, hideout set, fold  2 :  0.5832090942912816\n",
      "Prediction length on validation set, GBM Regressor, fold  2 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  2 :  18062\n",
      "\n",
      "Fold  3\n",
      "RMSLE GBM Regressor, validation set, fold  3 :  0.5601378679997298\n",
      "RMSLE GBM Regressor, hideout set, fold  3 :  0.5853159037128044\n",
      "Prediction length on validation set, GBM Regressor, fold  3 :  1465\n",
      "Prediction length on test set, GBM Regressor, fold  3 :  18062\n",
      "Finished CV at  2018-02-06 14:53:35.132623\n",
      "Finished average test set predictions at  2018-02-06 14:53:35.132932\n"
     ]
    }
   ],
   "source": [
    "print(\"Started CV at \", dt.datetime.now())\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n",
    "    X_test = testes\n",
    "    print(\"\\nFold \", i)\n",
    "\n",
    "    fit_model = model2.fit(X_train, y_train)\n",
    "    pred = model2.predict(X_valid)\n",
    "    print('RMSLE GBM Regressor, validation set, fold ', i, ': ', RMSLE(y_valid, pred))\n",
    "\n",
    "    pred_hideout = model2.predict(X_hideout)\n",
    "    print('RMSLE GBM Regressor, hideout set, fold ', i, ': ', RMSLE(y_hideout, pred_hideout))\n",
    "    print('Prediction length on validation set, GBM Regressor, fold ', i, ': ', len(pred))\n",
    "    # Accumulate test set predictions\n",
    "\n",
    "    pred = model2.predict(X_test)\n",
    "    print('Prediction length on test set, GBM Regressor, fold ', i, ': ', len(pred))\n",
    "    y_test_pred2 += pred\n",
    "\n",
    "    del X_test, X_train, X_valid, y_train\n",
    "\n",
    "print(\"Finished CV at \", dt.datetime.now())\n",
    "\n",
    "y_test_pred2 /= K  # Average test set predictions\n",
    "print(\"Finished average test set predictions at \", dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': 200, \n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 200,\n",
    "        'min_samples_leaf': 50,\n",
    "        'learning_rate': 0.2,\n",
    "        'max_features':  'sqrt',\n",
    "        'subsample': 0.8,\n",
    "        'loss': 'ls'}\n",
    "\n",
    "model3 = XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred3 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started CV at  2018-02-06 14:53:35.178109\n",
      "\n",
      "Fold  0\n",
      "RMSLE GBM Regressor, validation set, fold  0 :  0.4820664774298244\n",
      "RMSLE GBM Regressor, hideout set, fold  0 :  0.46676638040007257\n",
      "Prediction length on validation set, GBM Regressor, fold  0 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  0 :  18062\n",
      "\n",
      "Fold  1\n",
      "RMSLE GBM Regressor, validation set, fold  1 :  0.4762476114370208\n",
      "RMSLE GBM Regressor, hideout set, fold  1 :  0.4849414211919609\n",
      "Prediction length on validation set, GBM Regressor, fold  1 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  1 :  18062\n",
      "\n",
      "Fold  2\n",
      "RMSLE GBM Regressor, validation set, fold  2 :  0.4727376461376971\n",
      "RMSLE GBM Regressor, hideout set, fold  2 :  0.47255336167752104\n",
      "Prediction length on validation set, GBM Regressor, fold  2 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  2 :  18062\n",
      "\n",
      "Fold  3\n",
      "RMSLE GBM Regressor, validation set, fold  3 :  0.48835520363576895\n",
      "RMSLE GBM Regressor, hideout set, fold  3 :  0.5003288638662243\n",
      "Prediction length on validation set, GBM Regressor, fold  3 :  1465\n",
      "Prediction length on test set, GBM Regressor, fold  3 :  18062\n",
      "Finished CV at  2018-02-06 14:54:06.522977\n",
      "Finished average test set predictions at  2018-02-06 14:54:06.523492\n"
     ]
    }
   ],
   "source": [
    "print(\"Started CV at \", dt.datetime.now())\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n",
    "    X_test = testes\n",
    "    print(\"\\nFold \", i)\n",
    "\n",
    "    fit_model = model3.fit(X_train, y_train)\n",
    "    pred = model3.predict(X_valid)\n",
    "    print('RMSLE GBM Regressor, validation set, fold ', i, ': ', RMSLE(y_valid, pred))\n",
    "\n",
    "    pred_hideout = model3.predict(X_hideout)\n",
    "    print('RMSLE GBM Regressor, hideout set, fold ', i, ': ', RMSLE(y_hideout, pred_hideout))\n",
    "    print('Prediction length on validation set, GBM Regressor, fold ', i, ': ', len(pred))\n",
    "    # Accumulate test set predictions\n",
    "\n",
    "    pred = model3.predict(X_test)\n",
    "    print('Prediction length on test set, GBM Regressor, fold ', i, ': ', len(pred))\n",
    "    y_test_pred3 += pred\n",
    "\n",
    "    del X_test, X_train, X_valid, y_train\n",
    "\n",
    "print(\"Finished CV at \", dt.datetime.now())\n",
    "\n",
    "y_test_pred3 /= K  # Average test set predictions\n",
    "print(\"Finished average test set predictions at \", dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#LGBMだけ入れるデータを少し加工\n",
    "X = train[col]\n",
    "y = pd.DataFrame()\n",
    "y['visitors'] = np.log1p(train['visitors'].values)\n",
    "testes =test[col]\n",
    "X.sort_index(axis=1, inplace=True)\n",
    "y.sort_index(axis=1,inplace=True)\n",
    "testes.sort_index(axis=1,inplace=True)\n",
    "X, X_hideout, y, y_hideout = model_selection.train_test_split(X, y, test_size = 0.13, random_state = 42)\n",
    "y = y['visitors']\n",
    "y_hideout = y_hideout['visitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {'learning_rate': 0.05, \n",
    "        'n_estimators': 900,\n",
    "         'max_depth' : 8,\n",
    "         'boosting_type': 'gbdt',\n",
    "         'num_leaves' : 80,\n",
    "         'max_bin' : 255,\n",
    "         'seed' : 42,\n",
    "         'nthread' : -1,\n",
    "         'silent' : True}\n",
    "\n",
    "model4 = lgb.LGBMRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred4 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/sklearn.py:278: LGBMDeprecationWarning: The `seed` parameter is deprecated and will be removed in 2.0.12 version. Please use `random_state` instead.\n",
      "  'Please use `random_state` instead.', LGBMDeprecationWarning)\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/sklearn.py:281: LGBMDeprecationWarning: The `nthread` parameter is deprecated and will be removed in 2.0.12 version. Please use `n_jobs` instead.\n",
      "  'Please use `n_jobs` instead.', LGBMDeprecationWarning)\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started CV at  2018-02-06 14:54:06.812276\n",
      "\n",
      "Fold  0\n",
      "RMSLE GBM Regressor, validation set, fold  0 :  0.45361773127407196\n",
      "RMSLE GBM Regressor, hideout set, fold  0 :  0.4468174985613663\n",
      "Prediction length on validation set, GBM Regressor, fold  0 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  0 :  18062\n",
      "\n",
      "Fold  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/sklearn.py:278: LGBMDeprecationWarning: The `seed` parameter is deprecated and will be removed in 2.0.12 version. Please use `random_state` instead.\n",
      "  'Please use `random_state` instead.', LGBMDeprecationWarning)\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/sklearn.py:281: LGBMDeprecationWarning: The `nthread` parameter is deprecated and will be removed in 2.0.12 version. Please use `n_jobs` instead.\n",
      "  'Please use `n_jobs` instead.', LGBMDeprecationWarning)\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE GBM Regressor, validation set, fold  1 :  0.4388016153477257\n",
      "RMSLE GBM Regressor, hideout set, fold  1 :  0.45805777988922913\n",
      "Prediction length on validation set, GBM Regressor, fold  1 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  1 :  18062\n",
      "\n",
      "Fold  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/sklearn.py:278: LGBMDeprecationWarning: The `seed` parameter is deprecated and will be removed in 2.0.12 version. Please use `random_state` instead.\n",
      "  'Please use `random_state` instead.', LGBMDeprecationWarning)\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/sklearn.py:281: LGBMDeprecationWarning: The `nthread` parameter is deprecated and will be removed in 2.0.12 version. Please use `n_jobs` instead.\n",
      "  'Please use `n_jobs` instead.', LGBMDeprecationWarning)\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE GBM Regressor, validation set, fold  2 :  0.4446085213118169\n",
      "RMSLE GBM Regressor, hideout set, fold  2 :  0.45312883017780575\n",
      "Prediction length on validation set, GBM Regressor, fold  2 :  1466\n",
      "Prediction length on test set, GBM Regressor, fold  2 :  18062\n",
      "\n",
      "Fold  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/sklearn.py:278: LGBMDeprecationWarning: The `seed` parameter is deprecated and will be removed in 2.0.12 version. Please use `random_state` instead.\n",
      "  'Please use `random_state` instead.', LGBMDeprecationWarning)\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/sklearn.py:281: LGBMDeprecationWarning: The `nthread` parameter is deprecated and will be removed in 2.0.12 version. Please use `n_jobs` instead.\n",
      "  'Please use `n_jobs` instead.', LGBMDeprecationWarning)\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE GBM Regressor, validation set, fold  3 :  0.44880941054143975\n",
      "RMSLE GBM Regressor, hideout set, fold  3 :  0.457049025099983\n",
      "Prediction length on validation set, GBM Regressor, fold  3 :  1465\n",
      "Prediction length on test set, GBM Regressor, fold  3 :  18062\n",
      "Finished CV at  2018-02-06 14:54:34.531476\n",
      "Finished average test set predictions at  2018-02-06 14:54:34.532753\n"
     ]
    }
   ],
   "source": [
    "print(\"Started CV at \", dt.datetime.now())\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n",
    "    X_test = testes\n",
    "    print(\"\\nFold \", i)\n",
    "\n",
    "    fit_model = model4.fit(X_train, y_train)\n",
    "    pred = model4.predict(X_valid)\n",
    "    print('RMSLE GBM Regressor, validation set, fold ', i, ': ', RMSLE(y_valid, pred))\n",
    "\n",
    "    pred_hideout = model4.predict(X_hideout)\n",
    "    print('RMSLE GBM Regressor, hideout set, fold ', i, ': ', RMSLE(y_hideout, pred_hideout))\n",
    "    print('Prediction length on validation set, GBM Regressor, fold ', i, ': ', len(pred))\n",
    "    # Accumulate test set predictions\n",
    "\n",
    "    pred = model4.predict(X_test)\n",
    "    print('Prediction length on test set, GBM Regressor, fold ', i, ': ', len(pred))\n",
    "    y_test_pred4 += pred\n",
    "\n",
    "    del X_test, X_train, X_valid, y_train\n",
    "\n",
    "print(\"Finished CV at \", dt.datetime.now())\n",
    "\n",
    "y_test_pred4 /= K  # Average test set predictions\n",
    "print(\"Finished average test set predictions at \", dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#モデル２のpredだけ２次元で出てくるので加工\n",
    "dataset = np.zeros(shape=(len(y_test_pred2), 1))\n",
    "feature_names = ['visitors']\n",
    "tmp = pd.DataFrame(dataset,columns=feature_names)\n",
    "tmp['visitors'] = y_test_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre4 = model4.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19812,)\n",
      "(12207,)\n",
      "(18062,)\n"
     ]
    }
   ],
   "source": [
    "print(pred_513.shape)\n",
    "print(pred_316.shape)\n",
    "print(pred_gw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_513 =  y_test_pred1*0.3 + tmp['visitors'] *0.05 + y_test_pred3*0.1+ y_test_pred4*0.35+preds5*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_316 =  y_test_pred1*0.3 + tmp['visitors'] *0.05 + y_test_pred3*0.1+ y_test_pred4*0.35+preds5*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_gw =  y_test_pred1*0.3 + tmp['visitors'] *0.15 + y_test_pred3*0.2+ y_test_pred4*0.35#+preds5*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18062,)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_gw = pd.read_csv('/Users/suzukishinji/kaggle/recluit/sample_submission-3.csv')\n",
    "store_gw['visitors'] =pred_gw\n",
    "store_gw = store_gw.fillna(0)\n",
    "store_316 = pd.read_csv('/Users/suzukishinji/kaggle/recluit/tes_store_316.csv')\n",
    "store_316['visitors'] =pred_316 \n",
    "store_513 = pd.read_csv('/Users/suzukishinji/kaggle/recluit/tes_store_513.csv')\n",
    "store_513['visitors'] =pred_513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32014</th>\n",
       "      <td>air_fff68b929994bfbd_2017-05-27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32015</th>\n",
       "      <td>air_fff68b929994bfbd_2017-05-28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32016</th>\n",
       "      <td>air_fff68b929994bfbd_2017-05-29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32017</th>\n",
       "      <td>air_fff68b929994bfbd_2017-05-30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32018</th>\n",
       "      <td>air_fff68b929994bfbd_2017-05-31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  visitors\n",
       "32014  air_fff68b929994bfbd_2017-05-27       0.0\n",
       "32015  air_fff68b929994bfbd_2017-05-28       0.0\n",
       "32016  air_fff68b929994bfbd_2017-05-29       0.0\n",
       "32017  air_fff68b929994bfbd_2017-05-30       0.0\n",
       "32018  air_fff68b929994bfbd_2017-05-31       0.0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_gw.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_gw = store_gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>1.312121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>1.321203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>1.318761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>1.314564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>1.302656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23  1.312121\n",
       "1  air_00a91d42b08b08d9_2017-04-24  1.321203\n",
       "2  air_00a91d42b08b08d9_2017-04-25  1.318761\n",
       "3  air_00a91d42b08b08d9_2017-04-26  1.314564\n",
       "4  air_00a91d42b08b08d9_2017-04-27  1.302656"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_gw.rename(columns ={'visitors':'gw_visitors'})\n",
    "temp_gw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_store = pd.concat([store_316,store_513])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/Users/suzukishinji/kaggle/recluit/sample_submission-3.csv')\n",
    "test_air_store_id = sample['id']\n",
    "sub_stores = pd.DataFrame()\n",
    "sub_stores[\"id\"] = test_air_store_id\n",
    "sub_stores[\"visitors\"] = test['visitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>all_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0241aa3964b7f861_2017-04-23</td>\n",
       "      <td>2.210916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0241aa3964b7f861_2017-04-24</td>\n",
       "      <td>2.150173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861_2017-04-25</td>\n",
       "      <td>2.138857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0241aa3964b7f861_2017-04-26</td>\n",
       "      <td>2.209877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_0241aa3964b7f861_2017-04-27</td>\n",
       "      <td>1.307983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  all_visitors\n",
       "0  air_0241aa3964b7f861_2017-04-23      2.210916\n",
       "1  air_0241aa3964b7f861_2017-04-24      2.150173\n",
       "2  air_0241aa3964b7f861_2017-04-25      2.138857\n",
       "3  air_0241aa3964b7f861_2017-04-26      2.209877\n",
       "4  air_0241aa3964b7f861_2017-04-27      1.307983"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_all = all_store.rename(columns ={'visitors':'all_visitors'})\n",
    "rename_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>all_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>1.312121</td>\n",
       "      <td>1.400415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>1.321203</td>\n",
       "      <td>3.106879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>1.318761</td>\n",
       "      <td>3.299502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>1.314564</td>\n",
       "      <td>3.355776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>1.302656</td>\n",
       "      <td>3.446238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors  all_visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23  1.312121      1.400415\n",
       "1  air_00a91d42b08b08d9_2017-04-24  1.321203      3.106879\n",
       "2  air_00a91d42b08b08d9_2017-04-25  1.318761      3.299502\n",
       "3  air_00a91d42b08b08d9_2017-04-26  1.314564      3.355776\n",
       "4  air_00a91d42b08b08d9_2017-04-27  1.302656      3.446238"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_all = pd.merge(store_gw, rename_all,on=('id'), how='left')\n",
    "all_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>all_visitors</th>\n",
       "      <th>sub_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>1.382756</td>\n",
       "      <td>1.400415</td>\n",
       "      <td>1.396883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>2.749744</td>\n",
       "      <td>3.106879</td>\n",
       "      <td>3.035452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>2.903354</td>\n",
       "      <td>3.299502</td>\n",
       "      <td>3.220273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>2.947533</td>\n",
       "      <td>3.355776</td>\n",
       "      <td>3.274127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>3.017521</td>\n",
       "      <td>3.446238</td>\n",
       "      <td>3.360494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors  all_visitors  sub_visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23  1.382756      1.400415      1.396883\n",
       "1  air_00a91d42b08b08d9_2017-04-24  2.749744      3.106879      3.035452\n",
       "2  air_00a91d42b08b08d9_2017-04-25  2.903354      3.299502      3.220273\n",
       "3  air_00a91d42b08b08d9_2017-04-26  2.947533      3.355776      3.274127\n",
       "4  air_00a91d42b08b08d9_2017-04-27  3.017521      3.446238      3.360494"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_all['sub_visitors'] = all_all['visitors']*0.2 + all_all['all_visitors']*0.8\n",
    "all_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>1.396883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>3.035452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>3.220273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>3.274127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>3.360494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23  1.396883\n",
       "1  air_00a91d42b08b08d9_2017-04-24  3.035452\n",
       "2  air_00a91d42b08b08d9_2017-04-25  3.220273\n",
       "3  air_00a91d42b08b08d9_2017-04-26  3.274127\n",
       "4  air_00a91d42b08b08d9_2017-04-27  3.360494"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = all_all.drop(['visitors','all_visitors'], axis = 1)\n",
    "all_store = temp.rename(columns ={'sub_visitors':'visitors'})\n",
    "all_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>3.042581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>19.810383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>24.034946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>25.420152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>27.803428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id   visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23   3.042581\n",
       "1  air_00a91d42b08b08d9_2017-04-24  19.810383\n",
       "2  air_00a91d42b08b08d9_2017-04-25  24.034946\n",
       "3  air_00a91d42b08b08d9_2017-04-26  25.420152\n",
       "4  air_00a91d42b08b08d9_2017-04-27  27.803428"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =pd.read_csv('/Users/suzukishinji/kaggle/recluit/sample_submission-3.csv')\n",
    "test = test.drop('visitors', axis = 1)\n",
    "test = pd.merge(test, all_store,on=('id'), how='left')\n",
    "test = test.fillna(0)\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower =0.)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.157909899573929"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##割合変更（ここはあまり試していません）\n",
    "test['visitors'] =  y_test_pred1*0.3 + tmp['visitors'] *0.05 + y_test_pred3*0.1+ y_test_pred4*0.35+preds5*0.2\n",
    "#test['visitors'] = y_test_pred1*0.15+ tmp['visitors'] *0.1 + y_test_pred3*0.1+ y_test_pred4*0.4+preds5*0.25\n",
    "test['visitors'].mean()\n",
    "#test['visitors'] = np.expm1(test['visitors']).clip(lower =0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>3.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>19.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>23.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>27.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>30.793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23     3.058\n",
       "1  air_00a91d42b08b08d9_2017-04-24    19.907\n",
       "2  air_00a91d42b08b08d9_2017-04-25    23.276\n",
       "3  air_00a91d42b08b08d9_2017-04-26    27.628\n",
       "4  air_00a91d42b08b08d9_2017-04-27    30.793"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#単品のスコアを見るため\n",
    "test['visitors'] =  y_test_pred3\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower =0.)\n",
    "sample = pd.read_csv('/Users/suzukishinji/kaggle/recluit/sample_submission-3.csv')\n",
    "test_air_store_id = sample['id']\n",
    "df_result = pd.DataFrame()\n",
    "df_result[\"id\"] = test_air_store_id\n",
    "df_result[\"visitors\"] = test['visitors']\n",
    "df_result.to_csv(\"submit_0126_model3.csv\",index = False)\n",
    "submit_1 = pd.read_csv('/Users/suzukishinji/kaggle/recluit/submit_0126_model3.csv')\n",
    "submit_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ここからの加重平均は特にさわっていません\n",
    "sub1 = test[['id','visitors']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_info = pd.read_csv('/Users/suzukishinji/kaggle/recluit/date_info.csv')\n",
    "air_visit_data = pd.read_csv('/Users/suzukishinji/kaggle/recluit/air_visit_data.csv')\n",
    "sample_submission = pd.read_csv('/Users/suzukishinji/kaggle/recluit/sample_submission-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = { re.search('/([^/\\.]*)\\.csv', fn).group(1):\n",
    "       pd.read_csv(fn) for fn in glob.glob('/Users/suzukishinji/kaggle/recluit/*.csv')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, v in dfs.items(): locals()[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wkend_holidays = date_info.apply((lambda x: (x.day_of_week == 'Sunday' or x.day_of_week == 'Saturday') and x.holiday_flg ==1), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_info.loc[wkend_holidays, 'holiday_flg'] = 0\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info))**5\n",
    "visit_data = air_visit_data.merge(date_info, left_on= 'visit_date', right_on = 'calendar_date', how = 'left')\n",
    "visit_data.drop('calendar_date', axis = 1, inplace = True)\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "wmean = lambda x: ((x.weight * x.visitors).sum()/x.weight.sum())\n",
    "visitors = visit_data.groupby(['air_store_id', 'day_of_week', 'holiday_flg']).apply(wmean).reset_index()\n",
    "visitors.rename(columns = {0:'visitors'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission['air_store_id'] = sample_submission.id.map(lambda x : '_'.join(x.split('_')[:-1]))\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(visitors, on=[\n",
    "    'air_store_id', 'day_of_week', 'holiday_flg'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(visitors[visitors.holiday_flg == 0], on = ('air_store_id', 'day_of_week'),how = 'left')['visitors_y'].values\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), on = 'air_store_id',how = 'left')['visitors_y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission['visitors'] = sample_submission.visitors.map(pd.np.expm1)\n",
    "sub2 = sample_submission[['id', 'visitors']].copy()\n",
    "sub_merge = pd.merge(sub1, sub2, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_merge['visitors'] = 0.6*sub_merge['visitors_x'] + 0.4*sub_merge['visitors_y']*1.1\n",
    "sub_merge[['id', 'visitors']].to_csv('submission_0206_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>2.705548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>22.279748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>26.223145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>27.396496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>30.453901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id   visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23   2.705548\n",
       "1  air_00a91d42b08b08d9_2017-04-24  22.279748\n",
       "2  air_00a91d42b08b08d9_2017-04-25  26.223145\n",
       "3  air_00a91d42b08b08d9_2017-04-26  27.396496\n",
       "4  air_00a91d42b08b08d9_2017-04-27  30.453901"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ちゃんと出来ているか確認\n",
    "submit_1 = pd.read_csv('/Users/suzukishinji/kaggle/recluit/submission_0206_1.csv')\n",
    "submit_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32019 entries, 0 to 32018\n",
      "Data columns (total 2 columns):\n",
      "id          32019 non-null object\n",
      "visitors    32019 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 500.4+ KB\n"
     ]
    }
   ],
   "source": [
    "submit_1.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
