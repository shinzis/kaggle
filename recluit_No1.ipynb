{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "from datetime import date, timedelta\n",
    "from sklearn.preprocessing import  LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/suzukishinji/kaggle/recluit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_reserve = pd.read_csv(data_path + 'air_reserve.csv').rename(columns= {'air_store_id':'store_id'})\n",
    "hpg_reserve = pd.read_csv(data_path + 'hpg_reserve.csv').rename(columns={'hpg_store_id':'store_id'})\n",
    "air_store = pd.read_csv(data_path + 'air_store_info.csv').rename(columns={'air_store_id':'store_id'})\n",
    "hpg_store = pd.read_csv(data_path + 'hpg_store_info.csv').rename(columns={'hpg_store_id':'store_id'})\n",
    "air_visit = pd.read_csv(data_path + 'air_visit_data.csv').rename(columns={'air_store_id':'store_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_id_map = pd.read_csv(data_path + 'store_id_relation.csv').set_index('hpg_store_id',drop=False)\n",
    "date_info = pd.read_csv(data_path + 'date_info.csv').rename(columns={'calendar_date': 'visit_date'}).drop('day_of_week',axis=1)\n",
    "submission = pd.read_csv(data_path + 'sample_submission-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission['visit_date'] = submission['id'].str[-10:]\n",
    "submission['store_id'] = submission['id'].str[:-11]\n",
    "air_reserve['visit_date'] = air_reserve['visit_datetime'].str[:10]\n",
    "air_reserve['reserve_date'] = air_reserve['reserve_datetime'].str[:10]\n",
    "air_reserve['dow'] = pd.to_datetime(air_reserve['visit_date']).dt.dayofweek\n",
    "hpg_reserve['visit_date'] = hpg_reserve['visit_datetime'].str[:10]\n",
    "hpg_reserve['reserve_date'] = hpg_reserve['reserve_datetime'].str[:10]\n",
    "hpg_reserve['dow'] = pd.to_datetime(hpg_reserve['visit_date']).dt.dayofweek\n",
    "air_visit['id'] = air_visit['store_id'] + '_' + air_visit['visit_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_c63f6f42e088e50f</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>2016-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_dac72789163a3f47</td>\n",
       "      <td>2016-01-01 13:00:00</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_c8e24dcf51ca1eb5</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2016-01-01 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_24bb207e5fd49d4a</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_25291c542ebb3bc2</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store_id       visit_datetime     reserve_datetime  \\\n",
       "0  hpg_c63f6f42e088e50f  2016-01-01 11:00:00  2016-01-01 09:00:00   \n",
       "1  hpg_dac72789163a3f47  2016-01-01 13:00:00  2016-01-01 06:00:00   \n",
       "2  hpg_c8e24dcf51ca1eb5  2016-01-01 16:00:00  2016-01-01 14:00:00   \n",
       "3  hpg_24bb207e5fd49d4a  2016-01-01 17:00:00  2016-01-01 11:00:00   \n",
       "4  hpg_25291c542ebb3bc2  2016-01-01 17:00:00  2016-01-01 03:00:00   \n",
       "\n",
       "   reserve_visitors  visit_date reserve_date  dow  \n",
       "0                 1  2016-01-01   2016-01-01    4  \n",
       "1                 3  2016-01-01   2016-01-01    4  \n",
       "2                 2  2016-01-01   2016-01-01    4  \n",
       "3                 5  2016-01-01   2016-01-01    4  \n",
       "4                13  2016-01-01   2016-01-01    4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_reserve.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hpg_reserve['store_id'] = hpg_reserve['store_id'].map(store_id_map['air_store_id']).fillna(hpg_reserve['store_id'])\n",
    "hpg_store['store_id'] = hpg_store['store_id'].map(store_id_map['air_store_id']).fillna(hpg_store['store_id'])\n",
    "hpg_store.rename(columns={'hpg_genre_name':'air_genre_name','hpg_area_name':'air_area_name'},inplace=True)\n",
    "data = pd.concat([air_visit, submission]).copy()\n",
    "data['dow'] = pd.to_datetime(data['visit_date']).dt.dayofweek\n",
    "date_info['holiday_flg2'] = pd.to_datetime(date_info['visit_date']).dt.dayofweek\n",
    "date_info['holiday_flg2'] = ((date_info['holiday_flg2']>4) | (date_info['holiday_flg']==1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_store['air_area_name0'] = air_store['air_area_name'].apply(lambda x: x.split(' ')[0])\n",
    "lbl = LabelEncoder()\n",
    "air_store['air_genre_name'] = lbl.fit_transform(air_store['air_genre_name'])\n",
    "air_store['air_area_name0'] = lbl.fit_transform(air_store['air_area_name0'])\n",
    "\n",
    "data['visitors'] = np.log1p(data['visitors'])\n",
    "data = data.merge(air_store,on='store_id',how='left')\n",
    "data = data.merge(date_info[['visit_date','holiday_flg','holiday_flg2']], on=['visit_date'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat(L):\n",
    "    result = None\n",
    "    for l in L:\n",
    "        if result is None:\n",
    "            result = l\n",
    "        else:\n",
    "            try:\n",
    "                result[l.columns.tolist()] = l\n",
    "            except:\n",
    "                print(l.head())\n",
    "    return result\n",
    "\n",
    "def left_merge(data1,data2,on):\n",
    "    if type(on) != list:\n",
    "        on = [on]\n",
    "    if (set(on) & set(data2.columns)) != set(on):\n",
    "        data2_temp = data2.reset_index()\n",
    "    else:\n",
    "        data2_temp = data2.copy()\n",
    "    columns = [f for f in data2.columns if f not in on]\n",
    "    result = data1.merge(data2_temp,on=on,how='left')\n",
    "    result = result[columns]\n",
    "    return result\n",
    "\n",
    "\n",
    "def diff_of_days(day1, day2):\n",
    "    days = (parse(day1[:10]) - parse(day2[:10])).days\n",
    "    return days\n",
    "\n",
    "def date_add_days(start_date, days):\n",
    "    end_date = parse(start_date[:10]) + timedelta(days=days)\n",
    "    end_date = end_date.strftime('%Y-%m-%d')\n",
    "    return end_date\n",
    "\n",
    "\n",
    "def get_label(end_date,n_day):\n",
    "    label_end_date = date_add_days(end_date, n_day)\n",
    "    label = data[(data['visit_date'] < label_end_date) & (data['visit_date'] >= end_date)].copy()\n",
    "    label['end_date'] = end_date\n",
    "    label['diff_of_day'] = label['visit_date'].apply(lambda x: diff_of_days(x,end_date))\n",
    "    label['month'] = label['visit_date'].str[5:7].astype(int)\n",
    "    label['year'] = label['visit_date'].str[:4].astype(int)\n",
    "    for i in [3,2,1,-1]:\n",
    "        date_info_temp = date_info.copy()\n",
    "        date_info_temp['visit_date'] = date_info_temp['visit_date'].apply(lambda x: date_add_days(x,i))\n",
    "        date_info_temp.rename(columns={'holiday_flg':'ahead_holiday_{}'.format(i),'holiday_flg2':'ahead_holiday2_{}'.format(i)},inplace=True)\n",
    "        label = label.merge(date_info_temp, on=['visit_date'],how='left')\n",
    "    label = label.reset_index(drop=True)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_store_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0],-n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_temp.groupby(['store_id'], as_index=False)['visitors'].agg({'store_min{}'.format(n_day): 'min',\n",
    "                                                                             'store_mean{}'.format(n_day): 'mean',\n",
    "                                                                             'store_median{}'.format(n_day): 'median',\n",
    "                                                                             'store_max{}'.format(n_day): 'max',\n",
    "                                                                             'store_count{}'.format(n_day): 'count',\n",
    "                                                                             'store_std{}'.format(n_day): 'std',\n",
    "                                                                             'store_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['store_id']).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_store_exp_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_temp['visit_date'] = data_temp['visit_date'].apply(lambda x: diff_of_days(key[0],x))\n",
    "    data_temp['weight'] = data_temp['visit_date'].apply(lambda x: 0.985**x)\n",
    "    data_temp['visitors'] = data_temp['visitors'] * data_temp['weight']\n",
    "    result1 = data_temp.groupby(['store_id'], as_index=False)['visitors'].agg({'store_exp_mean{}'.format(n_day): 'sum'})\n",
    "    result2 = data_temp.groupby(['store_id'], as_index=False)['weight'].agg({'store_exp_weight_sum{}'.format(n_day): 'sum'})\n",
    "    result = result1.merge(result2, on=['store_id'], how='left')\n",
    "    result['store_exp_mean{}'.format(n_day)] = result['store_exp_mean{}'.format(n_day)]/result['store_exp_weight_sum{}'.format(n_day)]\n",
    "    result = left_merge(label, result, on=['store_id']).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def get_store_week_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_temp.groupby(['store_id', 'dow'], as_index=False)['visitors'].agg({'store_dow_min{}'.format(n_day): 'min',\n",
    "                                                                                     'store_dow_mean{}'.format(n_day): 'mean',\n",
    "                                                                                     'store_dow_median{}'.format(n_day): 'median',\n",
    "                                                                                     'store_dow_max{}'.format(n_day): 'max',\n",
    "                                                                                     'store_dow_count{}'.format(n_day): 'count',\n",
    "                                                                                     'store_dow_std{}'.format(n_day): 'std',\n",
    "                                                                                     'store_dow_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['store_id', 'dow']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_store_week_diff_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_temp.set_index(['store_id','visit_date'])['visitors'].unstack()\n",
    "    result = result.diff(axis=1).iloc[:,1:]\n",
    "    c = result.columns\n",
    "    result['store_diff_mean'] = np.abs(result[c]).mean(axis=1)\n",
    "    result['store_diff_std'] = result[c].std(axis=1)\n",
    "    result['store_diff_max'] = result[c].max(axis=1)\n",
    "    result['store_diff_min'] = result[c].min(axis=1)\n",
    "    result = left_merge(label, result[['store_diff_mean', 'store_diff_std', 'store_diff_max', 'store_diff_min']],on=['store_id']).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_store_all_week_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result_temp = data_temp.groupby(['store_id', 'dow'],as_index=False)['visitors'].agg({'store_dow_mean{}'.format(n_day): 'mean',\n",
    "                                                                     'store_dow_median{}'.format(n_day): 'median',\n",
    "                                                                     'store_dow_sum{}'.format(n_day): 'max',\n",
    "                                                                     'store_dow_count{}'.format(n_day): 'count'})\n",
    "    result = pd.DataFrame()\n",
    "    for i in range(7):\n",
    "        result_sub = result_temp[result_temp['dow']==i].copy()\n",
    "        result_sub = result_sub.set_index('store_id')\n",
    "        result_sub = result_sub.add_prefix(str(i))\n",
    "        result_sub = left_merge(label, result_sub, on=['store_id']).fillna(0)\n",
    "        result = pd.concat([result,result_sub],axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def get_store_week_exp_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_temp['visit_date'] = data_temp['visit_date'].apply(lambda x: diff_of_days(key[0],x))\n",
    "    data_temp['visitors2'] = data_temp['visitors']\n",
    "    result = None\n",
    "    for i in [0.9,0.95,0.97,0.98,0.985,0.99,0.999,0.9999]:\n",
    "        data_temp['weight'] = data_temp['visit_date'].apply(lambda x: i**x)\n",
    "        data_temp['visitors1'] = data_temp['visitors'] * data_temp['weight']\n",
    "        data_temp['visitors2'] = data_temp['visitors2'] * data_temp['weight']\n",
    "        result1 = data_temp.groupby(['store_id', 'dow'], as_index=False)['visitors1'].agg({'store_dow_exp_mean{}_{}'.format(n_day,i): 'sum'})\n",
    "        result3 = data_temp.groupby(['store_id', 'dow'], as_index=False)['visitors2'].agg({'store_dow_exp_mean2{}_{}'.format(n_day, i): 'sum'})\n",
    "        result2 = data_temp.groupby(['store_id', 'dow'], as_index=False)['weight'].agg({'store_dow_exp_weight_sum{}_{}'.format(n_day,i): 'sum'})\n",
    "        result_temp = result1.merge(result2, on=['store_id', 'dow'], how='left')\n",
    "        result_temp = result_temp.merge(result3, on=['store_id', 'dow'], how='left')\n",
    "        result_temp['store_dow_exp_mean{}_{}'.format(n_day,i)] = result_temp['store_dow_exp_mean{}_{}'.format(n_day,i)]/result_temp['store_dow_exp_weight_sum{}_{}'.format(n_day,i)]\n",
    "        result_temp['store_dow_exp_mean2{}_{}'.format(n_day, i)] = result_temp[ 'store_dow_exp_mean2{}_{}'.format(n_day, i)]/result_temp['store_dow_exp_weight_sum{}_{}'.format(n_day, i)]\n",
    "        if result is None:\n",
    "            result = result_temp\n",
    "        else:\n",
    "            result = result.merge(result_temp,on=['store_id','dow'],how='left')\n",
    "    result = left_merge(label, result, on=['store_id', 'dow']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_store_holiday_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result1 = data_temp.groupby(['store_id', 'holiday_flg'], as_index=False)['visitors'].agg(\n",
    "        {'store_holiday_min{}'.format(n_day): 'min',\n",
    "         'store_holiday_mean{}'.format(n_day): 'mean',\n",
    "         'store_holiday_median{}'.format(n_day): 'median',\n",
    "         'store_holiday_max{}'.format(n_day): 'max',\n",
    "         'store_holiday_count{}'.format(n_day): 'count',\n",
    "         'store_holiday_std{}'.format(n_day): 'std',\n",
    "         'store_holiday_skew{}'.format(n_day): 'skew'})\n",
    "    result1 = left_merge(label, result1, on=['store_id', 'holiday_flg']).fillna(0)\n",
    "    result2 = data_temp.groupby(['store_id', 'holiday_flg2'], as_index=False)['visitors'].agg(\n",
    "        {'store_holiday2_min{}'.format(n_day): 'min',\n",
    "         'store_holiday2_mean{}'.format(n_day): 'mean',\n",
    "         'store_holiday2_median{}'.format(n_day): 'median',\n",
    "         'store_holiday2_max{}'.format(n_day): 'max',\n",
    "         'store_holiday2_count{}'.format(n_day): 'count',\n",
    "         'store_holiday2_std{}'.format(n_day): 'std',\n",
    "         'store_holiday2_skew{}'.format(n_day): 'skew'})\n",
    "    result2 = left_merge(label, result2, on=['store_id', 'holiday_flg2']).fillna(0)\n",
    "    result = pd.concat([result1, result2], axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_genre_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0],-n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_temp.groupby(['air_genre_name'], as_index=False)['visitors'].agg({'genre_min{}'.format(n_day): 'min',\n",
    "                                                                             'genre_mean{}'.format(n_day): 'mean',\n",
    "                                                                             'genre_median{}'.format(n_day): 'median',\n",
    "                                                                             'genre_max{}'.format(n_day): 'max',\n",
    "                                                                             'genre_count{}'.format(n_day): 'count',\n",
    "                                                                             'genre_std{}'.format(n_day): 'std',\n",
    "                                                                             'genre_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['air_genre_name']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genre_exp_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_temp['visit_date'] = data_temp['visit_date'].apply(lambda x: diff_of_days(key[0],x))\n",
    "    data_temp['weight'] = data_temp['visit_date'].apply(lambda x: 0.985**x)\n",
    "    data_temp['visitors'] = data_temp['visitors'] * data_temp['weight']\n",
    "    result1 = data_temp.groupby(['air_genre_name'], as_index=False)['visitors'].agg({'genre_exp_mean{}'.format(n_day): 'sum'})\n",
    "    result2 = data_temp.groupby(['air_genre_name'], as_index=False)['weight'].agg({'genre_exp_weight_sum{}'.format(n_day): 'sum'})\n",
    "    result = result1.merge(result2, on=['air_genre_name'], how='left')\n",
    "    result['genre_exp_mean{}'.format(n_day)] = result['genre_exp_mean{}'.format(n_day)]/result['genre_exp_weight_sum{}'.format(n_day)]\n",
    "    result = left_merge(label, result, on=['air_genre_name']).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_genre_week_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_temp.groupby(['air_genre_name', 'dow'], as_index=False)['visitors'].agg({'genre_dow_min{}'.format(n_day): 'min',\n",
    "                                                                                         'genre_dow_mean{}'.format(n_day): 'mean',\n",
    "                                                                                         'genre_dow_median{}'.format(n_day): 'median',\n",
    "                                                                                         'genre_dow_max{}'.format(n_day): 'max',\n",
    "                                                                                         'genre_dow_count{}'.format(n_day): 'count',\n",
    "                                                                                         'genre_dow_std{}'.format(n_day): 'std',\n",
    "                                                                                         'genre_dow_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['air_genre_name', 'dow']).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_genre_week_exp_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_temp['visit_date'] = data_temp['visit_date'].apply(lambda x: diff_of_days(key[0],x))\n",
    "    data_temp['weight'] = data_temp['visit_date'].apply(lambda x: 0.985**x)\n",
    "    data_temp['visitors'] = data_temp['visitors'] * data_temp['weight']\n",
    "    result1 = data_temp.groupby(['air_genre_name', 'dow'], as_index=False)['visitors'].agg({'genre_dow_exp_mean{}'.format(n_day): 'sum'})\n",
    "    result2 = data_temp.groupby(['air_genre_name', 'dow'], as_index=False)['weight'].agg({'genre_dow_exp_weight_sum{}'.format(n_day): 'sum'})\n",
    "    result = result1.merge(result2, on=['air_genre_name', 'dow'], how='left')\n",
    "    result['genre_dow_exp_mean{}'.format(n_day)] = result['genre_dow_exp_mean{}'.format(n_day)]/result['genre_dow_exp_weight_sum{}'.format(n_day)]\n",
    "    result = left_merge(label, result, on=['air_genre_name', 'dow']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_first_last_time(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_temp = data_temp.sort_values('visit_date')\n",
    "    result = data_temp.groupby('store_id')['visit_date'].agg({'first_time':lambda x: diff_of_days(key[0],np.min(x)),\n",
    "                                                              'last_time':lambda x: diff_of_days(key[0],np.max(x)),})\n",
    "    result = left_merge(label, result, on=['store_id']).fillna(0)\n",
    "    return result\n",
    "\n",
    "def get_reserve_feat(label,key):\n",
    "    label_end_date = date_add_days(key[0], key[1])\n",
    "    air_reserve_temp = air_reserve[(air_reserve.visit_date >= key[0]) &             # key[0] 是'2017-04-23'\n",
    "                                   (air_reserve.visit_date < label_end_date) &      # label_end_date 是'2017-05-31'\n",
    "                                   (air_reserve.reserve_date < key[0])].copy()\n",
    "    air_reserve_temp = air_reserve_temp.merge(air_store,on='store_id',how='left')\n",
    "    air_reserve_temp['diff_time'] = (pd.to_datetime(air_reserve['visit_datetime'])-pd.to_datetime(air_reserve['reserve_datetime'])).dt.days\n",
    "    air_reserve_temp = air_reserve_temp.merge(air_store,on='store_id')\n",
    "    air_result = air_reserve_temp.groupby(['store_id', 'visit_date'])['reserve_visitors'].agg(\n",
    "        {'air_reserve_visitors': 'sum',\n",
    "         'air_reserve_count': 'count'})\n",
    "    air_store_diff_time_mean = air_reserve_temp.groupby(['store_id', 'visit_date'])['diff_time'].agg(\n",
    "        {'air_store_diff_time_mean': 'mean'})\n",
    "    air_diff_time_mean = air_reserve_temp.groupby(['visit_date'])['diff_time'].agg(\n",
    "        {'air_diff_time_mean': 'mean'})\n",
    "    air_result = air_result.unstack().fillna(0).stack()\n",
    "    air_date_result = air_reserve_temp.groupby(['visit_date'])['reserve_visitors'].agg({\n",
    "        'air_date_visitors': 'sum',\n",
    "        'air_date_count': 'count'})\n",
    "    hpg_reserve_temp = hpg_reserve[(hpg_reserve.visit_date >= key[0]) & (hpg_reserve.visit_date < label_end_date) & (hpg_reserve.reserve_date < key[0])].copy()\n",
    "    hpg_reserve_temp['diff_time'] = (pd.to_datetime(hpg_reserve['visit_datetime']) - pd.to_datetime(hpg_reserve['reserve_datetime'])).dt.days\n",
    "    hpg_result = hpg_reserve_temp.groupby(['store_id', 'visit_date'])['reserve_visitors'].agg({'hpg_reserve_visitors': 'sum',\n",
    "                                                                                               'hpg_reserve_count': 'count'})\n",
    "    hpg_result = hpg_result.unstack().fillna(0).stack()\n",
    "    hpg_date_result = hpg_reserve_temp.groupby(['visit_date'])['reserve_visitors'].agg({\n",
    "        'hpg_date_visitors': 'sum',\n",
    "        'hpg_date_count': 'count'})\n",
    "    hpg_store_diff_time_mean = hpg_reserve_temp.groupby(['store_id', 'visit_date'])['diff_time'].agg(\n",
    "        {'hpg_store_diff_time_mean': 'mean'})\n",
    "    hpg_diff_time_mean = hpg_reserve_temp.groupby(['visit_date'])['diff_time'].agg(\n",
    "        {'hpg_diff_time_mean': 'mean'})\n",
    "    air_result = left_merge(label, air_result, on=['store_id','visit_date']).fillna(0)\n",
    "    air_store_diff_time_mean = left_merge(label, air_store_diff_time_mean, on=['store_id', 'visit_date']).fillna(0)\n",
    "    hpg_result = left_merge(label, hpg_result, on=['store_id', 'visit_date']).fillna(0)\n",
    "    hpg_store_diff_time_mean = left_merge(label, hpg_store_diff_time_mean, on=['store_id', 'visit_date']).fillna(0)\n",
    "    air_date_result = left_merge(label, air_date_result, on=['visit_date']).fillna(0)\n",
    "    air_diff_time_mean = left_merge(label, air_diff_time_mean, on=['visit_date']).fillna(0)\n",
    "    hpg_date_result = left_merge(label, hpg_date_result, on=['visit_date']).fillna(0)\n",
    "    hpg_diff_time_mean = left_merge(label, hpg_diff_time_mean, on=['visit_date']).fillna(0)\n",
    "    result = pd.concat([air_result,hpg_result,air_date_result,hpg_date_result,air_store_diff_time_mean,\n",
    "                        hpg_store_diff_time_mean,air_diff_time_mean,hpg_diff_time_mean],axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_feat(result):\n",
    "    result['store_mean_14_28_rate'] = result['store_mean14']/(result['store_mean28']+0.01)\n",
    "    result['store_mean_28_56_rate'] = result['store_mean28'] / (result['store_mean56'] + 0.01)\n",
    "    result['store_mean_56_1000_rate'] = result['store_mean56'] / (result['store_mean1000'] + 0.01)\n",
    "    result['genre_mean_28_56_rate'] = result['genre_mean28'] / (result['genre_mean56'] + 0.01)\n",
    "    result['sgenre_mean_56_1000_rate'] = result['genre_mean56'] / (result['genre_mean1000'] + 0.01)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data key为：('2017-03-12', 39)\n",
      "add label\n",
      "make feature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:288: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:290: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:292: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:296: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:300: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:304: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:306: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:308: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/Users/suzukishinji/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:273: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge...\n",
      "data shape：(27728, 224)\n",
      "spending 156.90320801734924s\n",
      "data key为：('2017-03-05', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27705, 224)\n",
      "spending 158.96170711517334s\n",
      "data key为：('2017-02-26', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27745, 224)\n",
      "spending 135.91670179367065s\n",
      "data key为：('2017-02-19', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27696, 224)\n",
      "spending 142.02233791351318s\n",
      "data key为：('2017-02-12', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27596, 224)\n",
      "spending 146.81276297569275s\n",
      "data key为：('2017-02-05', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27561, 224)\n",
      "spending 146.92566180229187s\n",
      "data key为：('2017-01-29', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27511, 224)\n",
      "spending 139.33499312400818s\n",
      "data key为：('2017-01-22', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27474, 224)\n",
      "spending 140.14410185813904s\n",
      "data key为：('2017-01-15', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27389, 224)\n",
      "spending 133.83934497833252s\n",
      "data key为：('2017-01-08', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27201, 224)\n",
      "spending 128.96413803100586s\n",
      "data key为：('2017-01-01', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(25360, 224)\n",
      "spending 138.62815380096436s\n",
      "data key为：('2016-12-25', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(24721, 224)\n",
      "spending 133.17055201530457s\n",
      "data key为：('2016-12-18', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(24712, 224)\n",
      "spending 117.60214805603027s\n",
      "data key为：('2016-12-11', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(24761, 224)\n",
      "spending 118.72640800476074s\n",
      "data key为：('2016-12-04', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(24817, 224)\n",
      "spending 116.61848330497742s\n",
      "data key为：('2016-11-27', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(25184, 224)\n",
      "spending 115.55459094047546s\n",
      "data key为：('2016-11-20', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27458, 224)\n",
      "spending 109.94490098953247s\n",
      "data key为：('2016-11-13', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27418, 224)\n",
      "spending 110.0223159790039s\n",
      "data key为：('2016-11-06', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27251, 224)\n",
      "spending 105.25963711738586s\n",
      "data key为：('2016-10-30', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27116, 224)\n",
      "spending 102.0900411605835s\n",
      "data key为：('2016-10-23', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27085, 224)\n",
      "spending 96.56902194023132s\n",
      "data key为：('2016-10-16', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27093, 224)\n",
      "spending 91.83030343055725s\n",
      "data key为：('2016-10-09', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26987, 224)\n",
      "spending 90.78707098960876s\n",
      "data key为：('2016-10-02', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26949, 224)\n",
      "spending 94.84533405303955s\n",
      "data key为：('2016-09-25', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(27032, 224)\n",
      "spending 97.43031191825867s\n",
      "data key为：('2016-09-18', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26776, 222)\n",
      "spending 101.6992700099945s\n",
      "data key为：('2016-09-11', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26767, 224)\n",
      "spending 92.43520379066467s\n",
      "data key为：('2016-09-04', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26707, 224)\n",
      "spending 80.74246788024902s\n",
      "data key为：('2016-08-28', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26806, 224)\n",
      "spending 80.77849388122559s\n",
      "data key为：('2016-08-21', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26698, 224)\n",
      "spending 82.24591016769409s\n",
      "data key为：('2016-08-14', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26261, 224)\n",
      "spending 78.13519167900085s\n",
      "data key为：('2016-08-07', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26168, 224)\n",
      "spending 76.80023097991943s\n",
      "data key为：('2016-07-31', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26106, 222)\n",
      "spending 101.76756501197815s\n",
      "data key为：('2016-07-24', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26147, 224)\n",
      "spending 87.33873009681702s\n",
      "data key为：('2016-07-17', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26049, 224)\n",
      "spending 66.20657110214233s\n",
      "data key为：('2016-07-10', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26162, 224)\n",
      "spending 64.61095905303955s\n",
      "data key为：('2016-07-03', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(26806, 224)\n",
      "spending 72.36540508270264s\n",
      "data key为：('2016-06-26', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(24771, 224)\n",
      "spending 57.6615207195282s\n",
      "data key为：('2016-06-19', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(21834, 224)\n",
      "spending 63.38250803947449s\n",
      "data key为：('2016-06-12', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(18893, 224)\n",
      "spending 56.54220223426819s\n",
      "data key为：('2016-06-05', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(16061, 224)\n",
      "spending 53.70588803291321s\n",
      "data key为：('2016-05-29', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(13094, 224)\n",
      "spending 57.083428144454956s\n",
      "data key为：('2016-05-22', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10600, 224)\n",
      "spending 53.93692398071289s\n",
      "data key为：('2016-05-15', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10548, 224)\n",
      "spending 45.79910087585449s\n",
      "data key为：('2016-05-08', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10499, 224)\n",
      "spending 56.28626322746277s\n",
      "data key为：('2016-05-01', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10338, 224)\n",
      "spending 50.64056396484375s\n",
      "data key为：('2016-04-24', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10330, 224)\n",
      "spending 48.69285798072815s\n",
      "data key为：('2016-04-17', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10300, 224)\n",
      "spending 45.309850215911865s\n",
      "data key为：('2016-04-10', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10282, 224)\n",
      "spending 45.63319993019104s\n",
      "data key为：('2016-04-03', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10258, 224)\n",
      "spending 42.534404039382935s\n",
      "data key为：('2016-03-27', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10346, 224)\n",
      "spending 44.274340867996216s\n",
      "data key为：('2016-03-20', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10382, 224)\n",
      "spending 57.67801594734192s\n",
      "data key为：('2016-03-13', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10342, 224)\n",
      "spending 45.10793399810791s\n",
      "data key为：('2016-03-06', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10314, 224)\n",
      "spending 44.07252025604248s\n",
      "data key为：('2016-02-28', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10318, 224)\n",
      "spending 46.27307081222534s\n",
      "data key为：('2016-02-21', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10302, 224)\n",
      "spending 41.89655780792236s\n",
      "data key为：('2016-02-14', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10242, 224)\n",
      "spending 37.14675807952881s\n",
      "data key为：('2016-02-07', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10243, 224)\n",
      "spending 34.61579179763794s\n",
      "data key为：('2017-03-19', 35)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(24969, 224)\n",
      "spending 174.13006615638733s\n",
      "data key为：('2017-03-26', 28)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(20049, 224)\n",
      "spending 188.76676392555237s\n",
      "data key为：('2017-04-02', 21)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(14999, 224)\n",
      "spending 169.91688203811646s\n",
      "data key为：('2017-04-09', 14)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(10008, 224)\n",
      "spending 175.04011011123657s\n",
      "data key为：('2017-04-16', 7)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(5012, 224)\n",
      "spending 180.65258383750916s\n",
      "data key为：('2017-04-23', 39)\n",
      "add label\n",
      "make feature...\n",
      "merge...\n",
      "data shape：(32019, 224)\n",
      "spending 189.5562310218811s\n",
      "训练用时1615.377559185028秒\n"
     ]
    }
   ],
   "source": [
    "def make_feats(end_date,n_day):\n",
    "    t0 = time.time()\n",
    "    key = end_date,n_day\n",
    "    print('data key为：{}'.format(key))\n",
    "    print('add label')\n",
    "    label = get_label(end_date,n_day)\n",
    "\n",
    "    print('make feature...')\n",
    "    result = [label]\n",
    "    result.append(get_store_visitor_feat(label, key, 1000))        # store features\n",
    "    result.append(get_store_visitor_feat(label, key, 56))          # store features\n",
    "    result.append(get_store_visitor_feat(label, key, 28))          # store features\n",
    "    result.append(get_store_visitor_feat(label, key, 14))          # store features\n",
    "    result.append(get_store_exp_visitor_feat(label, key, 1000))    # store exp features\n",
    "    result.append(get_store_week_feat(label, key, 1000))           # store dow features\n",
    "    result.append(get_store_week_feat(label, key, 56))             # store dow features\n",
    "    result.append(get_store_week_feat(label, key, 28))             # store dow features\n",
    "    result.append(get_store_week_feat(label, key, 14))             # store dow features\n",
    "    result.append(get_store_week_diff_feat(label, key, 58))       # store dow diff features\n",
    "    result.append(get_store_week_diff_feat(label, key, 1000))      # store dow diff features\n",
    "    result.append(get_store_all_week_feat(label, key, 1000))       # store all week feat\n",
    "    result.append(get_store_week_exp_feat(label, key, 1000))       # store dow exp feat\n",
    "    result.append(get_store_holiday_feat(label, key, 1000))        # store holiday feat\n",
    "\n",
    "    result.append(get_genre_visitor_feat(label, key, 1000))         # genre feature\n",
    "    result.append(get_genre_visitor_feat(label, key, 56))           # genre feature\n",
    "    result.append(get_genre_visitor_feat(label, key, 28))           # genre feature\n",
    "    result.append(get_genre_exp_visitor_feat(label, key, 1000))     # genre feature\n",
    "    result.append(get_genre_week_feat(label, key, 1000))            # genre dow feature\n",
    "    result.append(get_genre_week_feat(label, key, 56))              # genre dow feature\n",
    "    result.append(get_genre_week_feat(label, key, 28))              # genre dow feature\n",
    "    result.append(get_genre_week_exp_feat(label, key, 1000))        # genre dow exp feature\n",
    "\n",
    "    result.append(get_reserve_feat(label,key))                      # air_reserve\n",
    "    result.append(get_first_last_time(label,key,1000))             # first time and last time\n",
    "\n",
    "    result.append(label)\n",
    "\n",
    "    print('merge...')\n",
    "    result = concat(result)\n",
    "\n",
    "    result = second_feat(result)\n",
    "\n",
    "    print('data shape：{}'.format(result.shape))\n",
    "    print('spending {}s'.format(time.time() - t0))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_feat = pd.DataFrame()\n",
    "start_date = '2017-03-12'\n",
    "for i in range(58):\n",
    "    train_feat_sub = make_feats(date_add_days(start_date, i*(-7)),39)\n",
    "    train_feat = pd.concat([train_feat,train_feat_sub])\n",
    "for i in range(1,6):\n",
    "    train_feat_sub = make_feats(date_add_days(start_date,i*(7)),42-(i*7))\n",
    "    train_feat = pd.concat([train_feat,train_feat_sub])\n",
    "test_feat = make_feats(date_add_days(start_date, 42),39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = [f for f in test_feat.columns if f not in (['id','store_id','visit_date','end_date','air_area_name','visitors','month'])]\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.02,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'sub_feature': 0.7,\n",
    "    'num_leaves': 60,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "t0 = time.time()\n",
    "lgb_train = lgb.Dataset(train_feat[predictors], train_feat['visitors'])\n",
    "lgb_test = lgb.Dataset(test_feat[predictors], test_feat['visitors'])\n",
    "\n",
    "gbm = lgb.train(params,lgb_train,2300)\n",
    "pred = gbm.predict(test_feat[predictors])\n",
    "\n",
    "print('训练用时{}秒'.format(time.time() - t0))\n",
    "subm = pd.DataFrame({'id':test_feat.store_id + '_' + test_feat.visit_date,'visitors':np.expm1(pred)})\n",
    "subm = submission[['id']].merge(subm,on='id',how='left').fillna(0)\n",
    "subm.to_csv(r'..\\sub{}.csv'.format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S')),\n",
    "                  index=False,  float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练用时2240.4022290706635秒\n"
     ]
    }
   ],
   "source": [
    "print('训练用时{}秒'.format(time.time() - t0))\n",
    "subm = pd.DataFrame({'id':test_feat.store_id + '_' + test_feat.visit_date,'visitors':np.expm1(pred)})\n",
    "subm = submission[['id']].merge(subm,on='id',how='left').fillna(0)\n",
    "subm.to_csv(r'sub{}.csv'.format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S')),\n",
    "                  index=False,  float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
